# ğŸ¤– DevMind

**DevMind** is a context-aware AI assistant for developers that runs in your terminal. It uses LLMs (like GPT-4 or Code Llama) to explain code, suggest fixes, analyze logs, and generate commands based on your working environment.

> Think of it as `copilot`, but for your terminal â€“ with deep integration into your codebase, shell, and dev tools.

## List of Commands

| Command             | Description                          |
| ------------------- | ------------------------------------ |
| `devmind chat`      | Chat with your project (With memory) |
| `devmind explain`   | Explain a source code file           |
| `devmind summarize` | Summarize code, logs, or text        |
| `devmind generate`  | Generate files based on descriptions |

## ğŸš€ Features

- ğŸ§‘â€ğŸ’» Chat with devmind ask any questions
- ğŸ§  Memory for context-aware conversations
- ğŸ“œ Explain source code files (`.go`, `.py`, `.js`...)
- ğŸ“– Summarize code, logs, or text
- ğŸ› ï¸ Generate shell commands, Dockerfiles, Makefiles
- ğŸ”Œ Pluggable backends: Ollama, (in Development): OpenAI

## ğŸ“¦ Example Usage

```bash
$ devmind chat what did we discussed in the last chat?
"Last time, we discussed the new feature for user authentication..."

$ devmind chat what is the purpose of this function?
"This function handles user login by validating credentials and generating a token..."

$ devmind generate create a Dockerfile for a Go web server
"FROM golang:1.21...."

$ devmind explain --file main.go --line 10-15
"This function is responsible for handling user login requests. It takes the username and password as input, validates them, and returns a token if successful..."

$ devmind summarize --file main.go
"This Go program initializes a context with signal handling for graceful shutdown. It sets up..."
```

## ğŸ“ Project Structure

```
devmind/
â”œâ”€â”€â”€bin
â”œâ”€â”€â”€cmd                 # CLI commands
â”‚   â””â”€â”€â”€ui              # UI elements (Spinner)
â”œâ”€â”€â”€config              # code for config
â”œâ”€â”€â”€internal
â”‚   â”œâ”€â”€â”€agent           # Agents for LLM
â”‚   â”‚   â”œâ”€â”€â”€ollama
â”‚   â”‚   â”œâ”€â”€â”€openai
â”‚   â”‚   â””â”€â”€â”€types
â”‚   â”œâ”€â”€â”€consumer        # LLM consumer
â”‚   â”œâ”€â”€â”€handlers        # handlers for different commands
â”‚   â”œâ”€â”€â”€logger          # logging and error handling
â”‚   â”œâ”€â”€â”€memory          # code for chat memory
â”‚   â”‚   â””â”€â”€â”€chat
â”‚   â””â”€â”€â”€utils           # Shell wrappers, file utils
â””â”€â”€ main.go
```

## âš™ï¸ Requirements

| Component       | Required For                    |
| --------------- | ------------------------------- |
| Go 1.24+        | CLI Tool                        |
| Ollama Endpoint | endpoint where Ollama is hosted |

## ğŸ’¡ Features

| Capability            | Description                                     |
| --------------------- | ----------------------------------------------- |
| âœ… Chat Continuity    | Context-aware conversations stored in memory    |
| âœ… Response Streaming | Stream response as it is generated              |
| âœ… Responsive UX      | Spinner to show progress and status updates     |
| âœ… Code summarization | Explain Go/Python/JS files and code sections    |
| âœ… Log diagnosis      | Parse and interpret crash/error logs            |
| âœ… Script generation  | Generate shell commands, Dockerfiles, Makefiles |
| âœ… File summarization | Summarize code, logs, or text files             |
| âœ… Multi-backend LLMs | Use Ollama, (OpenAI, Claude planned)            |
| ğŸ”’ Privacy-first      | Full local-only mode available                  |

## ğŸ§  Memory System

Currently, DevMind has a **basic memory system** that stores chat history in a file. This allows for context-aware conversations and helps the AI remember previous interactions.

Future plan: **Summarize and store chat history** for better context in conversations.

- After each chat or command, DevMind **spawns a background summarizer**.
- Summaries are stored inside `summaries/context.txt`.
- Future prompts **inject recent memory** to improve response continuity.

âœ… Non-blocking summarization
âœ… Fast startup and exit
âœ… Future upgrade path for semantic search memory

## ğŸ§  Supported LLMs

- âœ… Local Ollama models (CodeLlama, Mistral, Phi)
- âœ… OpenAI (gpt-3.5, gpt-4) _(planned)_
- âœ… Anthropic (Claude) _(planned)_

## ğŸ§‘â€ğŸ’» Author

Made with Go, LLMs, and caffeine by [@vinit-chauhan](https://github.com/vinit-chauhan)

## ğŸ“„ License

MIT Â© Vinit Chauhan
